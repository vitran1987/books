3.4 Raptor Mini Và Mô Hình Tiết Kiệm: Quy Tắc 80/20 Trong Trí Tuệ Nhân Tạo
Không ai có thể quên được cảm giác choáng váng của Jason Kim khi nhìn vào hóa đơn trí tuệ nhân tạo tháng đầu tiên. Số tiền một nghìn hai trăm đô la – gần bằng toàn bộ doanh thu của công ty khởi nghiệp chatbot chăm sóc khách hàng mà anh dồn tâm huyết xây dựng – khiến Jason phải ngồi lặng hàng giờ, kiểm tra lại từng con số, không tin vào mắt mình. Anh từng tin rằng, sử dụng mô hình trí tuệ nhân tạo mạnh nhất cho mọi câu hỏi của khách hàng sẽ mang lại trải nghiệm tuyệt vời, giữ chân người dùng và giúp công ty phát triển. Quả thật, khách hàng rất hài lòng với câu trả lời, nhưng với trung bình hai nghìn lượt hỏi mỗi ngày và mức giá cao ngất ngưởng của mô hình hiện đại, Jason nhận ra mình đang lỗ nặng trên từng tương tác – một mô hình kinh doanh không thể tồn tại lâu dài.

Trong lúc bế tắc, Jason quyết định phân tích kỹ từng loại câu hỏi mà khách hàng gửi đến. Điều anh phát hiện vừa khiến anh bất ngờ, vừa có chút tiếc nuối: hơn bảy mươi phần trăm câu hỏi cực kỳ đơn giản – như “Giờ làm việc của bạn là gì?”, “Làm sao để đổi mật khẩu?”, “Tôi có thể theo dõi đơn hàng ở đâu?” – những câu hỏi mà bất kỳ mô hình trí tuệ nhân tạo cơ bản nào cũng trả lời hoàn hảo. Jason ví mình như người dùng siêu xe Ferrari để đi giao bánh pizza – quá lãng phí. Chỉ khoảng mười lăm phần trăm câu hỏi thực sự phức tạp, đòi hỏi suy luận nhiều bước hoặc kiến thức chuyên sâu về sản phẩm, mới cần đến sức mạnh của mô hình đắt tiền.

Phát hiện này đã mở ra cho Jason một góc nhìn hoàn toàn mới về cách ứng dụng trí tuệ nhân tạo: quy tắc tám mươi – hai mươi áp dụng hoàn hảo cho lĩnh vực này. Tám mươi phần trăm công việc đủ đơn giản để các mô hình nhẹ, giá rẻ xử lý xuất sắc. Chỉ hai mươi phần trăm còn lại mới thực sự cần đến mô hình mạnh, chi phí cao. Bí quyết để xây dựng doanh nghiệp ứng dụng trí tuệ nhân tạo bền vững không phải là dùng mô hình tốt nhất cho mọi việc, mà là chọn đúng mô hình cho từng nhiệm vụ – điều mà Jason gọi là “định tuyến thông minh”.

Raptor Mini: Nhanh, Rẻ, Và Đủ Tốt
Khi GitHub Copilot ra mắt bản cập nhật lớn vào tháng 11 năm 2025, ít ai chú ý đến một tính năng nhỏ nhưng lại tạo ra thay đổi lớn cho những người khởi nghiệp quan tâm đến chi phí: Raptor Mini – mô hình trí tuệ nhân tạo nhẹ, được thiết kế riêng cho các tác vụ đơn giản, số lượng lớn. Các bài kiểm tra cho thấy Raptor Mini không thể giải các bài toán Olympic, không sáng tạo nội dung tiếp thị giàu cảm xúc, cũng không xử lý các yêu cầu đa phương tiện phức tạp. Nhưng điều mà Raptor Mini làm xuất sắc là giải quyết các công việc lập trình thường ngày với tốc độ cực nhanh và chi phí cực thấp – chỉ khoảng một đến hai đô la cho một triệu từ, rẻ hơn mười đến hai mươi lần so với mô hình cao cấp.

Elena Rodriguez, một lập trình viên độc lập xây dựng công cụ tự động hóa cho các doanh nghiệp thương mại điện tử nhỏ, là người đầu tiên áp dụng Raptor Mini và chia sẻ phân tích chi phí chi tiết khiến nhiều nhà sáng lập phải suy nghĩ lại toàn bộ chiến lược trí tuệ nhân tạo. Công cụ của Elena tự động tạo mô tả sản phẩm, xử lý đánh giá khách hàng, viết bài đăng mạng xã hội và trả lời các câu hỏi hỗ trợ cơ bản. Ban đầu, cô sử dụng mô hình cao cấp cho mọi tác vụ, hóa đơn hàng tháng lên tới sáu trăm đô la cho mười nghìn khách hàng – mức chi phí không thể duy trì với giá bán hai mươi đô la mỗi khách.

Sau khi áp dụng định tuyến thông minh, để Raptor Mini xử lý các tác vụ đơn giản, bức tranh chi phí thay đổi hoàn toàn: Raptor Mini đảm nhận bảy nghìn yêu cầu (mô tả sản phẩm đơn giản, trả lời câu hỏi thường gặp, bài đăng mạng xã hội cơ bản) với chi phí chỉ khoảng hai mươi đô la mỗi tháng. Mô hình cao cấp chỉ xử lý hai nghìn yêu cầu phức tạp (nội dung tiếp thị sáng tạo, phân tích đánh giá chi tiết, vấn đề khách hàng khó) với chi phí một trăm hai mươi đô la. Mô hình đa phương tiện xử lý một nghìn yêu cầu liên quan đến hình ảnh với chi phí năm mươi đô la. Tổng chi phí hàng tháng giảm từ sáu trăm xuống còn một trăm chín mươi đô la – tiết kiệm bốn trăm mười đô la mỗi tháng, tương đương sáu mươi tám phần trăm, mà chất lượng vẫn được giữ nguyên hoặc thậm chí cải thiện ở hầu hết các trường hợp.

Kết quả kiểm tra chất lượng mà Elena thực hiện cho thấy: với các mô tả sản phẩm đơn giản, khách hàng không nhận ra sự khác biệt giữa Raptor Mini và mô hình cao cấp – cả hai đều được chấm điểm bốn phẩy một trên năm. Tốc độ phản hồi còn tăng lên rõ rệt – Raptor Mini trả lời dưới một giây, trong khi mô hình cũ mất ba đến năm giây, tạo ra trải nghiệm mượt mà hơn hẳn. Chỉ với các nội dung tiếp thị đòi hỏi sáng tạo và cảm xúc sâu sắc, sự khác biệt mới xuất hiện – và đó cũng là lúc hệ thống tự động chuyển sang mô hình cao cấp hơn.


### Những Lựa Chọn Tiết Kiệm Khác: Hệ Sinh Thái Đa Dạng Cho Người Khởi Nghiệp

Không chỉ có Raptor Mini mới giúp các doanh nghiệp tiết kiệm chi phí vận hành trí tuệ nhân tạo. Thị trường hiện nay đã xuất hiện nhiều mô hình khác, mỗi loại lại phù hợp với một nhóm nhu cầu và ngân sách riêng, tạo nên một hệ sinh thái đa dạng, giúp người dùng có thể lựa chọn linh hoạt hơn bao giờ hết.

GPT-4o-Mini của OpenAI là một ví dụ điển hình cho sự cân bằng giữa chất lượng và giá thành. Với mức giá chỉ khoảng không phẩy mười lăm đô la cho một triệu từ, mô hình này mạnh hơn hẳn Raptor Mini ở những tác vụ đòi hỏi suy luận trung bình, nhưng vẫn chỉ bằng một phần mười chi phí của các mô hình cao cấp nhất. Maria Santos – người sáng lập ứng dụng học tiếng Anh cho người Việt – đã lựa chọn GPT-4o-Mini để tạo ra hàng nghìn câu luyện tập mỗi ngày, sửa lỗi ngữ pháp cơ bản và xây dựng các bài kiểm tra đơn giản. Những tác vụ này không quá đơn giản để giao cho Raptor Mini, nhưng cũng không đủ phức tạp để phải dùng đến mô hình đắt tiền nhất. Kết quả, chất lượng nội dung vẫn đảm bảo, tốc độ phản hồi nhanh hơn, tỷ lệ giữ chân học viên còn tăng lên, trong khi chi phí giảm mạnh từ ba trăm xuống chỉ còn hai mươi lăm đô la mỗi tháng.

Gemini Flash – lựa chọn siêu tốc và tiết kiệm của Google – có giá chỉ khoảng không phẩy không bảy lăm đô la cho một triệu từ, phù hợp nhất với các tác vụ số lượng cực lớn nhưng đơn giản như dịch thuật cơ bản, phân loại văn bản, hoặc truy xuất thông tin nhanh. Một ứng dụng tổng hợp tin tức xử lý năm mươi nghìn bài báo mỗi ngày đã chuyển sang dùng Gemini Flash, giúp chi phí hàng tháng giảm từ hai nghìn đô la (khi dùng mô hình cao cấp) xuống chỉ còn năm mươi đô la, mà độ chính xác vẫn đạt chín mươi hai phần trăm – chỉ thấp hơn một chút so với mức chín mươi sáu phần trăm trước đây, nhưng người dùng hoàn toàn không nhận ra sự khác biệt.

Bảng so sánh dưới đây giúp bạn hình dung rõ hơn về các mô hình tiết kiệm phổ biến hiện nay:

**GPT-5.1**: Mười đến hai mươi đô la cho một triệu từ. Tốc độ: chậm (năm đến mười giây). Chất lượng: xuất sắc. Phù hợp với các tác vụ phức tạp, lập trình nâng cao, giải toán, phân tích chiến lược.

**Gemini 3 Pro**: Hai phẩy năm đến bảy phẩy năm đô la cho một triệu từ. Tốc độ: trung bình (hai đến năm giây). Chất lượng: rất tốt. Phù hợp với nội dung tiếng Việt, tác vụ đa phương tiện, xử lý ngữ cảnh dài, tạo giao diện người dùng.

**Claude Opus 4.5**: Mười lăm đô la cho một triệu từ. Tốc độ: trung bình (ba đến sáu giây). Chất lượng: xuất sắc cho sáng tạo. Phù hợp với sáng tác, giáo dục, giao tiếp đồng cảm, nội dung tiếp thị.

**Raptor Mini**: Một đến hai đô la cho một triệu từ. Tốc độ: rất nhanh (dưới một giây). Chất lượng: tốt cho tác vụ đơn giản. Phù hợp với hoàn thiện mã, trả lời câu hỏi ngắn, tự động hóa thường nhật, xử lý khối lượng lớn.

**GPT-4o-Mini**: Không phẩy mười lăm đô la cho một triệu từ. Tốc độ: nhanh (một đến hai giây). Chất lượng: tốt. Phù hợp với tác vụ trung bình, cân bằng giữa hiệu năng và chi phí, ứng dụng đa mục đích.

**Gemini Flash**: Không phẩy không bảy lăm đô la cho một triệu từ. Tốc độ: cực nhanh (dưới một giây). Chất lượng: chấp nhận được. Phù hợp với tác vụ cực lớn, yêu cầu phản hồi tức thì, ngân sách hạn chế.


### Chiến Lược Định Tuyến Thông Minh: Xây Dựng Bộ Não Điều Phối Mô Hình

Sức mạnh thực sự của doanh nghiệp không nằm ở việc chọn một mô hình trí tuệ nhân tạo tốt nhất cho mọi tình huống, mà ở khả năng kết hợp linh hoạt nhiều mô hình khác nhau, giao đúng việc cho đúng “người”. Ý tưởng về một “bộ não điều phối” – một lớp logic trung gian tự động quyết định mô hình nào sẽ xử lý từng yêu cầu dựa trên đặc điểm cụ thể – đã trở thành bí quyết thành công của nhiều doanh nghiệp hiện đại.

David Zhang, người sáng lập nền tảng phân tích dữ liệu cho doanh nghiệp vừa và nhỏ, là một trong những người tiên phong xây dựng hệ thống định tuyến phức tạp và sẵn sàng chia sẻ kiến trúc với cộng đồng. Hệ thống của anh phân tích từng yêu cầu theo nhiều chiều trước khi quyết định chuyển đến mô hình nào:

**Nhận diện độ phức tạp**: Hệ thống quét nội dung yêu cầu để phát hiện dấu hiệu của các tác vụ phức tạp. Những từ khóa như “phân tích”, “tính toán”, “thiết kế”, “tối ưu”, “giải thích lý do” sẽ được xếp vào nhóm khó. Các câu hỏi đơn giản như “là gì”, “hiển thị”, “liệt kê” sẽ được chuyển cho mô hình nhẹ. Những yêu cầu trung bình như “so sánh”, “tóm tắt”, “dịch” sẽ vào nhóm giữa. Nhờ kết hợp nhận diện từ khóa và phân tích cấu trúc câu, hệ thống đạt độ chính xác lên tới chín mươi ba phần trăm khi phân loại.

**Nhận diện lĩnh vực**: Một số lĩnh vực đặc thù sẽ ưu tiên mô hình riêng. Ví dụ, các yêu cầu liên quan đến tiếng Việt sẽ tự động chuyển cho Gemini 3 Pro nhờ khả năng xử lý ngôn ngữ vượt trội. Các tác vụ sáng tạo như viết truyện, tiếp thị, email, blog sẽ ưu tiên Claude Opus. Câu hỏi kỹ thuật về lập trình sẽ được cân nhắc giữa GPT-5.1-Codex hoặc Raptor Mini tùy độ khó. Yêu cầu đa phương tiện như xử lý hình ảnh chỉ giao cho Gemini 3 Pro.

**Kiểm tra độ dài ngữ cảnh**: Những yêu cầu có ngữ cảnh rất dài – ví dụ phân tích cả tài liệu hoặc nhiều tệp cùng lúc – sẽ được chuyển cho các mô hình có bộ nhớ lớn như Gemini 3 Pro (một triệu từ) hoặc Claude Opus (hai trăm nghìn từ). Câu hỏi ngắn thì mô hình nào cũng xử lý được.

**Phân biệt thời gian thực và xử lý lô**: Các yêu cầu cần phản hồi tức thì sẽ ưu tiên mô hình nhanh nhất như Raptor Mini hoặc Gemini Flash. Những tác vụ xử lý theo lô, không gấp về thời gian, có thể dùng mô hình chậm hơn nhưng chất lượng cao hơn như GPT-5.1 hoặc Claude.

**Giám sát ngân sách**: Hệ thống luôn theo dõi chi tiêu hàng ngày và tự động điều chỉnh khi gần chạm ngưỡng ngân sách, chuyển nhiều yêu cầu hơn sang mô hình rẻ, đồng thời bảo vệ các tác vụ giá trị cao bằng mô hình tốt nhất.

Ví dụ thực tế: Khi người dùng gửi yêu cầu “Viết chú thích sáng tạo cho Instagram về lớp yoga mới giúp tĩnh tâm và an lạc”, hệ thống nhận diện đây là tác vụ sáng tạo, không phải tiếng Việt, độ dài vừa phải, không cần trả lời ngay lập tức, lại là nội dung hướng tới khách hàng nên xứng đáng dùng mô hình cao cấp. Kết quả: hệ thống chọn Claude Opus 4.5, chi phí chỉ khoảng không phẩy không ba đô la, chất lượng truyền cảm xuất sắc.

Một ví dụ khác: Khi khách hỏi “Chính sách hoàn tiền của bạn là gì?”, hệ thống xác định đây là câu hỏi thường gặp, ngắn, không cần ngôn ngữ đặc biệt, cần trả lời nhanh, giá trị thấp. Quyết định: chuyển cho Raptor Mini với câu trả lời đã lưu sẵn, chi phí chỉ không phẩy không không hai đô la, chất lượng hoàn toàn đáp ứng.


### Dự Báo Chi Phí Cho Các Kịch Bản Thực Tế

Việc dự đoán chi phí cho các mô hình trí tuệ nhân tạo là yếu tố sống còn trong hoạch định tài chính của bất kỳ doanh nghiệp nào. Dưới đây là ba kịch bản thực tế, đại diện cho các mô hình kinh doanh cá nhân ở nhiều quy mô khác nhau, giúp bạn hình dung rõ hơn về tác động của chiến lược định tuyến thông minh.

**Kịch bản A – Khởi nghiệp giáo dục trực tuyến (Bạn Giỏi):**
Giả sử bạn có mười nghìn học sinh, chủ yếu là học sinh Việt Nam. Mỗi tháng, hệ thống nhận bảy nghìn câu hỏi đơn giản (toán cơ bản, kiến thức nền tảng), hai nghìn câu hỏi phức tạp (giải toán nâng cao, nhận xét bài luận), một nghìn yêu cầu đa phương tiện (chấm bài viết tay, phân tích sơ đồ).

Nếu chỉ dùng mô hình cao cấp nhất cho tất cả:
Mười nghìn yêu cầu, trung bình hai nghìn từ mỗi yêu cầu, tổng cộng hai mươi triệu từ. Giá mười lăm đô la cho một triệu từ, tổng chi phí ba trăm đô la mỗi tháng. Hoạt động được nhưng quá tốn kém cho giai đoạn đầu.

Nếu áp dụng định tuyến thông minh:
- Bảy nghìn câu hỏi đơn giản → Raptor Mini: mười bốn triệu từ, chi phí mười bốn đô la
- Hai nghìn câu hỏi phức tạp → GPT-5.1: bốn triệu từ, chi phí sáu mươi đô la
- Một nghìn yêu cầu đa phương tiện → Gemini 3 Pro: hai triệu từ, chi phí mười đô la
- Tổng cộng: tám mươi bốn đô la mỗi tháng

Tiết kiệm được hai trăm mười sáu đô la mỗi tháng (bảy mươi hai phần trăm), tương đương hai nghìn năm trăm chín mươi hai đô la mỗi năm – đủ để thuê thêm cộng tác viên nội dung hoặc đầu tư cho marketing.

**Kịch bản B – Dịch vụ hỗ trợ khách hàng SaaS đang phát triển:**
Hai mươi nghìn khách hàng tạo ra một trăm nghìn phiếu hỗ trợ mỗi tháng. Trong đó, bảy mươi nghìn là câu hỏi thường gặp đơn giản, hai mươi nghìn là vấn đề trung bình, mười nghìn là vấn đề kỹ thuật phức tạp.

Nếu chỉ dùng GPT-4 cho tất cả:
Một trăm nghìn yêu cầu, trung bình một nghìn từ mỗi yêu cầu, tổng cộng một trăm triệu từ. Giá một đô la cho một triệu từ, tổng chi phí một trăm đô la. Nghe có vẻ hợp lý cho đến khi quy mô tăng lên.

Nếu tối ưu định tuyến:
- Bảy mươi nghìn câu hỏi thường gặp → Gemini Flash: bảy mươi triệu từ, chi phí năm đô la
- Hai mươi nghìn vấn đề trung bình → GPT-4o-Mini: hai mươi triệu từ, chi phí ba đô la
- Mười nghìn vấn đề phức tạp → Claude Opus: mười triệu từ, chi phí một trăm năm mươi đô la
- Tổng cộng: một trăm năm mươi tám đô la mỗi tháng

Thoạt nhìn có vẻ tốn hơn, nhưng chất lượng xử lý các vấn đề phức tạp tăng mạnh (dùng Claude thay vì GPT-4), tỷ lệ hài lòng của khách hàng tăng từ bảy mươi lăm lên chín mươi hai phần trăm, giảm tỷ lệ rời bỏ sáu phần trăm. Với giá trị vòng đời khách hàng trung bình một trăm hai mươi đô la, chỉ riêng việc giảm rời bỏ đã mang lại lợi ích hàng nghìn đô la mỗi tháng – khoản đầu tư thêm năm mươi tám đô la cho AI hoàn toàn xứng đáng.

**Kịch bản C – Công ty sản xuất nội dung quy mô vừa:**
Năm mươi khách hàng doanh nghiệp, mỗi tháng cần hai trăm sản phẩm nội dung. Cơ cấu: một trăm bài đăng mạng xã hội đơn giản, năm mươi bài blog trung bình, ba mươi bài phân tích chuyên sâu, hai mươi chiến dịch sáng tạo.

Nếu chỉ dùng mô hình cao cấp cho tất cả:
Hai trăm sản phẩm, trung bình năm nghìn từ mỗi sản phẩm, tổng cộng một tỷ từ. Giá mười lăm đô la cho một triệu từ, tổng chi phí mười lăm đô la mỗi tháng. Thực ra khá hợp lý, nhưng vẫn còn cơ hội tối ưu.

Nếu định tuyến tối ưu:
- Một trăm bài mạng xã hội → GPT-4o-Mini: năm trăm triệu từ, chi phí không phẩy không bảy năm đô la
- Năm mươi blog → Gemini 3 Pro: hai trăm năm mươi triệu từ, chi phí một phẩy hai năm đô la
- Năm mươi sản phẩm cao cấp (bài phân tích + chiến dịch) → Claude Opus: hai trăm năm mươi triệu từ, chi phí ba phẩy bảy năm đô la
- Tổng cộng: năm phẩy bảy năm đô la mỗi tháng

Tiết kiệm được chín phẩy hai năm đô la mỗi tháng (sáu mươi hai phần trăm). Đặc biệt, dùng Gemini 3 Pro cho blog nhắm tới thị trường Việt Nam giúp tăng tương tác lên hai mươi ba phần trăm nhờ nội dung phù hợp văn hóa, trong khi Claude vẫn giữ được chiều sâu cảm xúc cho các sản phẩm cao cấp. Hiệu quả cao hơn với chi phí thấp hơn – tối ưu lý tưởng cho doanh nghiệp.


### Khung Quyết Định: Xây Dựng Chiến Lược Định Tuyến Hiệu Quả

Để xây dựng một chiến lược định tuyến tối ưu, doanh nghiệp cần hiểu rõ thói quen sử dụng trí tuệ nhân tạo của mình và xác định đâu là yếu tố mang lại giá trị lớn nhất. Dưới đây là khung quyết định thực tiễn, đã được nhiều doanh nghiệp áp dụng thành công:

**Bước 1 – Kiểm toán thực tế sử dụng:** Theo dõi toàn bộ yêu cầu gửi đến hệ thống trong một tuần. Phân loại theo độ phức tạp, lĩnh vực, ngôn ngữ, mức độ cần phản hồi nhanh. Nhiều nhà sáng lập bất ngờ khi phát hiện có tới sáu mươi lăm đến bảy mươi lăm phần trăm yêu cầu đủ đơn giản để giao cho mô hình nhẹ.

**Bước 2 – Xác định ngưỡng chất lượng:** Không phải yêu cầu nào cũng quan trọng như nhau. Nội dung hướng tới khách hàng cần chất lượng cao hơn công cụ nội bộ. Tính năng tạo ra doanh thu xứng đáng dùng mô hình cao cấp, còn các tiện ích phụ có thể chấp nhận chất lượng vừa phải. Hãy xác định rõ tiêu chuẩn tối thiểu cho từng nhóm tác vụ.

**Bước 3 – Gán mô hình phù hợp cho từng nhóm:** Dựa trên kết quả kiểm thử và đánh giá, chọn mô hình tối ưu cho từng loại yêu cầu. Luôn có phương án dự phòng khi mô hình chính gặp sự cố hoặc vượt ngân sách. Đừng ngạc nhiên nếu đôi khi mô hình rẻ lại cho chất lượng ngang ngửa mô hình đắt ở một số trường hợp cụ thể.

**Bước 4 – Nâng cấp dần dần:** Bắt đầu thật thận trọng – chỉ dùng mô hình rẻ cho các tác vụ đơn giản rõ ràng. Khi đã tự tin, mở rộng phạm vi áp dụng. Luôn theo dõi sát các chỉ số chất lượng. Nếu phát hiện chất lượng giảm, hãy chuyển lại sang mô hình cao cấp cho nhóm đó.

**Bước 5 – Xây dựng vòng lặp phản hồi:** Theo dõi song song cả chi phí và chất lượng: mức độ hài lòng của khách, tỷ lệ hoàn thành tác vụ, số lỗi, chi tiêu hàng ngày/tháng. Điều chỉnh quy tắc định tuyến dựa trên dữ liệu thực tế, không dựa vào cảm tính. Thường xuyên thử nghiệm A/B với các nhóm tác vụ khó phân loại.

**Bước 6 – Đặt cảnh báo ngân sách:** Xác định giới hạn chi tiêu theo ngày, tuần, tháng. Khi gần chạm ngưỡng, hệ thống tự động chuyển nhiều tác vụ hơn sang mô hình rẻ, ưu tiên giữ chất lượng cho các yêu cầu quan trọng nhất. Nhờ đó, doanh nghiệp tránh được những hóa đơn bất ngờ mà vẫn đảm bảo dịch vụ cho khách hàng trọng tâm.

Jason Kim – người từng choáng váng với hóa đơn một nghìn hai trăm đô la – sau khi áp dụng chiến lược này đã giảm chi phí xuống còn một trăm chín mươi đô la mỗi tháng, đồng thời rút ngắn thời gian phản hồi trung bình tới bốn mươi phần trăm nhờ các mô hình nhẹ hơn. Hai năm sau, dù số lượng khách hàng tăng gấp mười lần, chi phí trí tuệ nhân tạo mỗi tháng chỉ là một nghìn một trăm đô la thay vì mười hai nghìn nếu vẫn dùng toàn mô hình cao cấp – mở ra con đường tăng trưởng bền vững và lợi nhuận thực sự.
