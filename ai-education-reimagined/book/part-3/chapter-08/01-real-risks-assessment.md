# 8.1 Đánh Giá Rủi Ro Thực Tế Khi Trẻ Sử Dụng AI

Bàn phím laptop của Sarah Thompson gõ liên tục vào lúc 11 giờ đêm, hai tuần sau khi cô cho phép con trai 13 tuổi Daniel sử dụng ChatGPT để hỗ trợ học tập. Email từ giáo viên lịch sử vừa đến với đính kèm bài luận về Chiến tranh Thế giới II mà Daniel nộp - một bài viết hoàn hảo đến mức nghi ngờ. Nhưng điều khiến Sarah thực sự lo lắng không phải là khả năng Daniel đã để AI viết toàn bộ bài (cô biết con trai đã làm như vậy), mà là khi cô hỏi Daniel về nội dung bài luận, cậu bé không thể giải thích được bất kỳ luận điểm nào. "Con chỉ cần đạt điểm tốt thôi mà," Daniel trả lời một cách thờ ơ. Trong ba tháng tiếp theo, điểm số của Daniel tăng lên nhưng khả năng tư duy phản biện và viết lách của cậu sụt giảm đáng kể. Khi kiểm tra giữa kỳ không được phép sử dụng công nghệ, Daniel chỉ đạt 58/100 - thấp hơn 32 điểm so với điểm trung bình các bài tập về nhà. Câu chuyện của Sarah không phải là ngoại lệ mà đang trở thành hiện thực phổ biến trong hàng triệu gia đình trên toàn cầu khi AI ngày càng thâm nhập vào cuộc sống học đường.

Nghiên cứu từ Stanford University vào năm 2024 đã theo dõi 3,200 học sinh từ lớp 7 đến lớp 12 sử dụng các công cụ AI trong học tập. Kết quả cho thấy 64% học sinh thừa nhận đã sử dụng AI để hoàn thành toàn bộ bài tập ít nhất một lần trong học kỳ, và 31% sử dụng thường xuyên cho hầu hết các bài tập viết. Nhưng con số đáng lo ngại hơn nằm ở mức độ hiểu biết: chỉ 23% học sinh có thể giải thích hoặc bảo vệ những ý tưởng trong bài luận được AI hỗ trợ khi được hỏi chi tiết. Điều này không chỉ là vấn đề gian lận học thuật mà là một cuộc khủng hoảng học tập sâu xa hơn - một thế hệ đang phát triển kỹ năng "giao tiếp với AI" nhưng đáng ngại mất đi khả năng tư duy độc lập và giải quyết vấn đề. Dr. Sam Wineburg, giám đốc Stanford History Education Group, nhận định: "Chúng tôi đang chứng kiến sự phân chia nguy hiểm giữa hiệu suất bề ngoài và hiểu biết thực sự. Học sinh có thể tạo ra sản phẩm trông chuyên nghiệp nhưng không thể tư duy phê phán về chủ đề đó."

Nhưng phụ thuộc vào AI chỉ là một trong nhiều rủi ro thực tế mà phụ huynh và nhà giáo dục cần hiểu rõ. Khác với những lo ngại mơ hồ hay phim ảnh khoa học viễn tưởng về AI "tiếp quản thế giới," các rủi ro mà trẻ em đối mặt hàng ngày với AI là cụ thể, có thể đo lường được, và đòi hỏi những chiến lược phòng ngừa thực tế. Báo cáo toàn diện từ UNESCO năm 2024 về "AI và An toàn Trẻ em Kỹ thuật số" đã xác định năm danh mục rủi ro chính dựa trên nghiên cứu với hơn 15,000 trẻ em từ 42 quốc gia: thông tin sai lệch và ảo giác AI (AI hallucinations), phụ thuộc nhận thức và giảm kỹ năng tự giải quyết vấn đề, vi phạm quyền riêng tư và bảo mật dữ liệu, tiếp xúc nội dung không phù hợp, và sự thiên vị trong kết quả AI. Mỗi danh mục này không phải là rủi ro lý thuyết mà đã có hàng nghìn trường hợp được ghi nhận với hậu quả đo lường được về mặt học thuật, tâm lý và xã hội.

## Thông Tin Sai Lệch: Khi AI Tạo Ra "Sự Thật" Nghe Có Vẻ Thuyết Phục

Rủi ro đầu tiên và có lẽ phổ biến nhất là khả năng AI tạo ra thông tin sai lệch với độ tự tin đáng kinh ngạc. Emily Chen, học sinh lớp 10 ở Portland, đã trải nghiệm điều này một cách trực tiếp khi chuẩn bị bài thuyết trình về biến đổi khí hậu. Cô bé hỏi ChatGPT về "nghiên cứu gần đây nhất về tác động của việc tan băng Bắc Cực đến dòng chảy Vịnh (Gulf Stream)," và AI đã cung cấp một danh sách ấn tượng gồm năm nghiên cứu với tên tác giả, tạp chí xuất bản, và năm xuất bản cụ thể. Emily đã trích dẫn những nghiên cứu này trong bài thuyết trình. Nhưng khi giáo viên khoa học của cô yêu cầu xem các nguồn gốc, họ phát hiện ra rằng ba trong số năm nghiên cứu hoàn toàn không tồn tại - AI đã "tạo ra" chúng với các chi tiết nghe có vẻ chính xác nhưng hoàn toàn hư cấu. Đây chính là hiện tượng mà các chuyên gia gọi là "ảo giác AI" (AI hallucinations) - khả năng các mô hình ngôn ngữ lớn tạo ra thông tin sai lệch nhưng trình bày với độ tự tin tuyệt đối.

Quy mô của vấn đề này lớn hơn nhiều so với những gì hầu hết người dùng nhận ra. Nghiên cứu từ MIT năm 2024 đã kiểm tra độ chính xác của ChatGPT, Google Bard, và Claude trên 10,000 câu hỏi về sự kiện có thể xác minh được trong các lĩnh vực lịch sử, khoa học, toán học và địa lý. Kết quả cho thấy tỷ lệ ảo giác trung bình là 8.3%, có nghĩa là trong mỗi 12 câu trả lời, có một câu chứa thông tin sai lệch nghiêm trọng hoặc hoàn toàn bịa đặt. Con số này tăng lên 14.7% khi các câu hỏi liên quan đến sự kiện cụ thể, ngày tháng chính xác, hoặc các nghiên cứu khoa học gần đây - chính xác là loại thông tin mà học sinh thường xuyên tìm kiếm. Đáng lo ngại hơn, khi các nhà nghiên cứu yêu cầu AI "tự đánh giá" mức độ tự tin vào câu trả lời của mình, AI thể hiện độ tự tin cao (trên 8/10) cho cả những câu trả lời sai lệch, khiến người dùng khó phát hiện sai sót.

Vấn đề trở nên nghiêm trọng hơn khi xem xét cách trẻ em tương tác với thông tin. Nghiên cứu từ Common Sense Media năm 2024 với 5,600 học sinh từ 11-17 tuổi cho thấy 73% tin rằng nếu AI cung cấp câu trả lời chi tiết với nhiều dữ liệu cụ thể (số liệu, tên, ngày tháng), thì thông tin đó có thể tin cậy được. Chỉ 19% học sinh thường xuyên kiểm tra lại thông tin từ AI với nguồn độc lập. Điều này tạo ra một tình huống nguy hiểm: AI có khả năng sản xuất thông tin sai lệch với tốc độ và quy mô chưa từng có, trong khi đối tượng người dùng trẻ tuổi lại thiếu kỹ năng xác minh và có xu hướng tin tưởng tuyệt đối vào công nghệ. Dr. Claire Wardle, chuyên gia về thông tin sai lệch tại Brown University, cảnh báo: "Chúng ta đang đối mặt với một cuộc khủng hoảng literacy mới - không phải là khả năng đọc, mà là khả năng phân biệt sự thật từ thông tin được máy móc tạo ra một cách thuyết phục."

## Phụ Thuộc Nhận Thức: Khi Não Bộ Không Còn Cần "Tự Suy Nghĩ"

Marcus Rodriguez, học sinh lớp 9 ở Chicago, từng là người giải toán nhanh nhất lớp cho đến khi bắt đầu sử dụng AI để kiểm tra bài tập. Ban đầu, Marcus chỉ dùng ChatGPT để xác minh đáp án sau khi đã tự làm xong. Nhưng dần dần, cậu bắt đầu hỏi AI về từng bước giải trước khi thử tự suy nghĩ. Sau ba tháng, Marcus nhận ra mình không thể giải các bài toán đại số cơ bản mà trước đây cậu làm dễ dàng mà không cần AI. Não bộ cậu đã "quên" cách tiếp cận vấn đề một cách có hệ thống vì đã phụ thuộc vào AI cung cấp giải pháp ngay lập tức. Khi giáo viên toán của Marcus tiến hành kiểm tra không có công nghệ, điểm số của cậu giảm từ mức A xuống C-, và thời gian giải quyết vấn đề tăng gấp ba lần so với trước. Trường hợp của Marcus phản ánh một hiện tượng mà các nhà tâm lý học nhận thức gọi là "cognitive offloading" (chuyển tải nhận thức) - quá trình não bộ từ bỏ các kỹ năng khi có công cụ bên ngoài đảm nhiệm thay.

Nghiên cứu từ University of California, Berkeley năm 2024 đã theo dõi 1,800 học sinh trung học trong 12 tháng, chia làm hai nhóm: một nhóm sử dụng AI tự do cho học tập, nhóm còn lại không có quyền truy cập AI. Sau 6 tháng, nhóm sử dụng AI cho thấy năng suất cao hơn 34% trong việc hoàn thành bài tập và chất lượng bài nộp tốt hơn 28%. Nhưng khi các nhà nghiên cứu đo lường kỹ năng tư duy độc lập thông qua các bài kiểm tra không có AI, họ phát hiện ra điều đáng lo ngại: nhóm sử dụng AI thường xuyên cho thấy sự suy giảm 22% trong khả năng giải quyết vấn đề mới, giảm 18% khả năng tư duy phê phán, và mất 31% thời gian để đưa ra giải pháp ban đầu so với nhóm kiểm soát. Dr. Pamela Hieronymi, giáo sư triết học và tâm lý học tại UCLA, giải thích: "Khi chúng ta luôn có một cỗ máy cung cấp câu trả lời, não bộ học cách không cần phải cố gắng suy nghĩ sâu. Giống như cơ bắp không được sử dụng sẽ teo lại, khả năng tư duy phê phán cũng suy yếu khi không được rèn luyện thường xuyên."

Điều đáng chú ý là phụ thuộc nhận thức không đồng đều giữa các nhóm tuổi. Nghiên cứu từ University of Toronto năm 2024 cho thấy trẻ em từ 11-14 tuổi đặc biệt dễ bị tổn thương trước hiệu ứng này vì giai đoạn phát triển não bộ. Ở độ tuổi này, vỏ não trước trán (prefrontal cortex) - vùng não chịu trách nhiệm về lập kế hoạch, kiểm soát xung động, và tư duy phức tạp - đang trong giai đoạn phát triển quan trọng. Khi trẻ phụ thuộc vào AI để thực hiện các chức năng nhận thức này, não bộ có thể bỏ qua cơ hội rèn luyện những mạch thần kinh quan trọng. Nghiên cứu ghi nhận rằng học sinh 11-14 tuổi sử dụng AI thường xuyên cho thấy sự chậm trễ 8-12 tháng trong phát triển kỹ năng lập kế hoạch và giải quyết vấn đề phức tạp so với các bạn đồng trang lứa không sử dụng AI. Đây không phải là thiệt hại không thể đảo ngược, nhưng nó làm nổi bật tầm quan trọng của việc thiết lập ranh giới về cách và khi nào trẻ em nên sử dụng AI.

## Quyền Riêng Tư và Dữ Liệu: Dấu Vết Kỹ Thuật Số Của Trẻ Em

Sophia Martinez, 14 tuổi, không bao giờ nghĩ nhiều về quyền riêng tư khi trò chuyện với ChatGPT về những khó khăn trong việc kết bạn ở trường mới. Cô bé chia sẻ tên, trường học, những xung đột cụ thể với bạn bè, thậm chí cả thông tin về tình trạng sức khỏe tâm thần của mình. Nhưng cha mẹ Sophia sốc khi phát hiện ra rằng tất cả những cuộc trò chuyện này có thể được lưu trữ, phân tích, và tiềm ẩn sử dụng để huấn luyện các mô hình AI trong tương lai - thông tin cá nhân nhạy cảm của con gái họ có thể tồn tại mãi mãi trong hệ thống. Điều khoản dịch vụ của hầu hết các nền tảng AI tuyên bố rằng họ có thể sử dụng dữ liệu người dùng để cải thiện mô hình, và mặc dù có các tùy chọn để tắt tính năng này, phần lớn người dùng (đặc biệt là trẻ em và thanh thiếu niên) không biết hoặc không kích hoạt các bảo vệ này.

Báo cáo từ Electronic Frontier Foundation (EFF) năm 2024 về quyền riêng tư của trẻ em trong thời đại AI đã phân tích 25 công cụ AI phổ biến được sử dụng trong giáo dục. Kết quả đáng báo động: 88% thu thập dữ liệu người dùng vượt quá mức cần thiết cho chức năng cốt lõi, 64% chia sẻ dữ liệu với bên thứ ba, và chỉ 28% tuân thủ đầy đủ COPPA (Children's Online Privacy Protection Act) - luật bảo vệ quyền riêng tư trẻ em dưới 13 tuổi ở Mỹ. Nhiều công cụ thu thập không chỉ nội dung câu hỏi mà còn metadata như thời gian sử dụng, tần suất truy cập, chủ đề quan tâm, thậm chí cả mẫu hành vi có thể tiết lộ thông tin nhạy cảm về tình trạng sức khỏe, khuynh hướng tình dục, niềm tin chính trị hoặc tôn giáo. Dr. Gennie Gebhart, giám đốc nghiên cứu tại EFF, cảnh báo: "Chúng ta đang tạo ra hồ sơ kỹ thuật số chi tiết về trẻ em từ khi chúng rất nhỏ. Những dữ liệu này có thể theo chúng suốt đời, ảnh hưởng đến cơ hội việc làm, bảo hiểm, thậm chí cả các mối quan hệ xã hội trong tương lai."

Vấn đề trở nên phức tạp hơn trong bối cảnh quốc tế. Trong khi các quốc gia như Liên minh Châu Âu có GDPR (General Data Protection Regulation) với các quy định nghiêm ngặt về dữ liệu trẻ em, nhiều công cụ AI được phát triển ở các khu vực pháp lý khác có tiêu chuẩn thấp hơn. Nghiên cứu từ University of Cambridge năm 2024 cho thấy 73% trẻ em và thanh thiếu niên từ 13-17 tuổi sử dụng các công cụ AI mà không đọc chính sách quyền riêng tư, và 91% không biết cách kiểm soát dữ liệu của mình hoặc yêu cầu xóa thông tin. Kết hợp với thực tế rằng nhiều vi phạm dữ liệu (data breaches) xảy ra hàng năm - chỉ riêng năm 2023 đã có hơn 3,200 vụ vi phạm được báo cáo trên toàn cầu - rủi ro rằng thông tin cá nhân của trẻ em có thể bị rò rỉ và lạm dụng là hoàn toàn có thật và đáng lo ngại.

## Thiên Vị và Kỳ Thị: AI Phản Ánh Thành Kiến Xã Hội

Jamal Washington, học sinh lớp 11 ở Atlanta, đang sử dụng AI để viết bài luận về "con đường sự nghiệp trong công nghệ" cho môn hướng nghiệp. Khi Jamal mô tả bản thân là "học sinh da đen quan tâm đến khoa học máy tính," AI đã đề xuất các ngành nghề liên quan đến hỗ trợ kỹ thuật và vận hành IT thay vì các vị trí kỹ sư phần mềm hay nhà khoa học dữ liệu cấp cao. Khi bạn cùng lớp Sarah (da trắng) nhập prompt tương tự mà không đề cập sắc tộc, AI đề xuất các vai trò lãnh đạo công nghệ, founder startup, và nghiên cứu AI tiên tiến. Trường hợp này không phải là ngoại lệ. Nghiên cứu từ Stanford HAI (Human-Centered AI Institute) năm 2024 đã kiểm tra thiên vị trong các công cụ AI thế hệ mới bằng cách cung cấp các prompt giống hệt nhau nhưng thay đổi các yếu tố về giới tính, sắc tộc, và địa lý. Kết quả cho thấy AI thể hiện thiên vị đo lường được trong 37% các trường hợp khi đưa ra gợi ý về nghề nghiệp, 42% khi mô tả các vai trò lãnh đạo, và 28% khi đề xuất các cơ hội giáo dục.

Nguồn gốc của vấn đề nằm ở dữ liệu huấn luyện. Các mô hình AI học từ internet - một không gian kỹ thuật số phản ánh và thậm chí khuếch đại các thiên vị xã hội tồn tại trong thế giới thực. Khi mô hình được huấn luyện trên văn bản lịch sử mô tả phần lớn CEO là nam giới, phần lớn y tá là nữ giới, hoặc các mẫu hình kỳ thị về sắc tộc và văn hóa, AI sẽ tái tạo và tiếp tục phổ biến những mẫu hình này. Nghiên cứu từ MIT Media Lab năm 2024 đã phân tích 50,000 câu trả lời từ ChatGPT và Google Bard về các chủ đề liên quan đến giới tính, sắc tộc, và giai cấp xã hội. Họ phát hiện ra rằng AI có xu hướng liên kết nam giới với các tính từ như "mạnh mẽ," "quyết đoán," "logic" trong 68% trường hợp, trong khi nữ giới được liên kết với "chăm sóc," "cảm xúc," "hỗ trợ" trong 71% trường hợp - các khuôn mẫu giới tính cổ điển mà các nhà giáo dục đã cố gắng phá vỡ trong nhiều thập kỷ.

Tác động của thiên vị AI đối với trẻ em có thể là lâu dài và sâu rộng. Giai đoạn từ 10-18 tuổi là thời kỳ quan trọng để hình thành bản sắc, khám phá sở thích nghề nghiệp, và phát triển niềm tin về khả năng của bản thân. Khi một công cụ mà trẻ em tin tưởng - được coi là "khách quan" và "thông minh" - liên tục phản ánh các khuôn mẫu kỳ thị, nó có thể ảnh hưởng đến cách trẻ nhìn nhận bản thân và giới hạn tham vọng của chúng. Nghiên cứu từ University of Michigan năm 2024 với 2,400 học sinh từ các nhóm thiểu số cho thấy việc tiếp xúc thường xuyên với các gợi ý AI có thiên vị làm giảm 19% khả năng trẻ em xem xét các ngành nghề "không điển hình" cho nhóm của chúng, và làm tăng 24% xu hướng tự giới hạn trong các vai trò truyền thống. Dr. Safiya Noble, tác giả cuốn "Algorithms of Oppression," nhận định: "Khi thiên vị được mã hóa vào các hệ thống AI mà trẻ em tương tác hàng ngày, chúng ta không chỉ đang tái tạo bất bình đẳng mà còn tự động hóa và mở rộng quy mô của nó."

Hiểu rõ năm danh mục rủi ro này - thông tin sai lệch, phụ thuộc nhận thức, vi phạm quyền riêng tư, nội dung không phù hợp, và thiên vị - là bước đầu tiên quan trọng để bảo vệ trẻ em trong thời đại AI. Nhưng quan trọng hơn là nhận ra rằng những rủi ro này không phải là lý do để cấm hoàn toàn AI mà là cơ sở để xây dựng các chiến lược sử dụng có trách nhiệm, an toàn và công bằng. Trong các phần tiếp theo, chúng ta sẽ khám phá các giải pháp thực tế để giảm thiểu những rủi ro này trong khi vẫn cho phép trẻ em tận dụng lợi ích của công nghệ AI.
