# Mô hình ReAct & Plan-and-Solve

## Khi chatbot đơn giản không đủ

Minh Anh, sinh viên năm ba chuyên ngành Kinh tế Quốc tế, đang loay hoay với kế hoạch chuẩn bị IELTS. Cô đã thử hỏi một chatbot thông thường: "Hãy giúp tôi lập kế hoạch học IELTS 3 tháng để đạt band 7.0". Câu trả lời trả về khá chung chung—một danh sách các gợi ý rời rạc về việc luyện từ vựng, nghe, đọc, viết mỗi ngày, nhưng không có lộ trình cụ thể, không có mốc thời gian kiểm tra, cũng chẳng rõ nên bắt đầu từ đâu. Minh Anh cảm thấy như mình vừa nhận được một tờ hướng dẫn chung chung, không thực sự giúp ích cho bản thân khi cần một lộ trình chi tiết, có tính thực thi.

Trong khi đó, một hệ thống Agent hoạt động theo mô hình ReAct (Reason + Act) có thể xử lý câu hỏi của Minh Anh hoàn toàn khác biệt. Thay vì chỉ trả lời một lần, Agent sẽ thực hiện một chuỗi các bước: đầu tiên nó suy luận (Thought) rằng cần biết trình độ hiện tại của người học, sau đó hành động (Action) bằng cách hỏi thêm thông tin—"Bạn đã thi thử IELTS bao giờ chưa? Hiện tại band điểm của bạn là bao nhiêu?"—rồi quan sát (Observation) câu trả lời của Minh Anh. Dựa trên thông tin đó, Agent tiếp tục suy luận để đưa ra kế hoạch chi tiết hơn: phân bổ thời gian mỗi tuần cho từng kỹ năng, đề xuất các tài liệu phù hợp, lên lịch kiểm tra định kỳ, và thậm chí gợi ý điều chỉnh chiến lược nếu tiến độ không đạt như mong đợi. Điều này không phải là phép màu, mà là kết quả của việc Agent áp dụng một quy trình tư duy-hành động liên tục, không chỉ dừng lại ở một câu trả lời tĩnh.

Mô hình ReAct, được giới thiệu bởi nhóm nghiên cứu từ Princeton và Google Research vào năm 2022, đánh dấu một bước ngoặt quan trọng trong thiết kế Agent thông minh. Trước đó, các chatbot thường chỉ hoạt động theo kiểu input-output đơn giản: nhận câu hỏi, tạo câu trả lời, xong việc. Nhưng trong thực tế, con người không làm việc như vậy. Khi đối mặt với một vấn đề phức tạp, chúng ta thường suy nghĩ, thực hiện hành động để thu thập thêm thông tin, quan sát kết quả, rồi suy nghĩ tiếp dựa trên những gì vừa học được. ReAct mô phỏng chính xác quy trình này bằng cách kết hợp Chain of Thought (chuỗi tư duy) với khả năng gọi Action (hành động) như tra cứu dữ liệu, chạy API, hoặc tương tác với môi trường bên ngoài.

Trong một nghiên cứu thực nghiệm được công bố tại hội nghị ICLR 2023, các Agent sử dụng ReAct đạt độ chính xác cao hơn 20% so với các phương pháp truyền thống khi giải quyết các bài toán đa bước như tra cứu thông tin, tổng hợp dữ liệu từ nhiều nguồn, và đưa ra quyết định dựa trên ngữ cảnh động. Điều này không phải vì mô hình ngôn ngữ lớn (LLM) đằng sau đột nhiên trở nên thông minh hơn, mà vì cách tổ chức quy trình làm việc của Agent đã thay đổi căn bản. Thay vì buộc mô hình phải "biết tất cả" ngay từ đầu, ReAct cho phép Agent học và điều chỉnh trong quá trình thực hiện nhiệm vụ, giống như một người chuyên nghiệp thực sự.

## Cơ chế hoạt động của ReAct

Để hiểu rõ hơn về ReAct, hãy xem xét một ví dụ cụ thể. Giả sử Agent nhận câu hỏi: "Công ty nào đang dẫn đầu thị trường chip AI vào năm 2024 và lý do là gì?" Một chatbot truyền thống có thể đưa ra câu trả lời dựa trên kiến thức được huấn luyện từ trước, nhưng nếu dữ liệu huấn luyện chỉ đến năm 2023, câu trả lời sẽ không còn chính xác. Ngược lại, Agent sử dụng ReAct sẽ thực hiện theo quy trình sau:

**Bước 1: Thought (Suy luận)** - Agent nhận ra rằng câu hỏi yêu cầu thông tin cập nhật về năm 2024, vốn không có trong dữ liệu huấn luyện của nó. Do đó, Agent quyết định cần tra cứu thông tin mới nhất từ nguồn bên ngoài.

**Bước 2: Action (Hành động)** - Agent gọi tool tìm kiếm trên web với query: "leading AI chip companies 2024 market share". Tool trả về một số kết quả, trong đó có bài báo từ Reuters cho biết NVIDIA chiếm 92% thị phần chip AI vào Q2/2024, xa hơn hẳn các đối thủ như AMD và Intel.

**Bước 3: Observation (Quan sát)** - Agent nhận thông tin từ tool và ghi nhận rằng NVIDIA là công ty dẫn đầu, với con số thị phần cực kỳ ấn tượng.

**Bước 4: Thought (Suy luận tiếp)** - Agent nhận thấy câu hỏi còn yêu cầu giải thích lý do. Thông tin vừa thu thập chưa đủ để trả lời phần này, nên Agent quyết định cần tra cứu thêm về chiến lược và sản phẩm của NVIDIA.

**Bước 5: Action (Hành động tiếp)** - Agent gọi tool tìm kiếm với query mới: "NVIDIA dominance AI chip market reasons 2024". Kết quả trả về các bài phân tích chuyên sâu, nêu rõ các yếu tố như kiến trúc GPU CUDA, hệ sinh thái phần mềm mạnh mẽ, và quan hệ đối tác chiến lược với các big tech như Microsoft, Google, Amazon.

**Bước 6: Observation (Quan sát tiếp)** - Agent tổng hợp các lý do chính: ưu thế công nghệ, hệ sinh thái phần mềm, và mạng lưới đối tác.

**Bước 7: Thought (Kết luận)** - Giờ đây Agent có đủ thông tin để trả lời đầy đủ câu hỏi ban đầu.

**Bước 8: Answer (Trả lời)** - Agent tạo câu trả lời chi tiết: "NVIDIA đang dẫn đầu thị trường chip AI vào năm 2024 với 92% thị phần. Lý do chính bao gồm kiến trúc GPU CUDA vượt trội, hệ sinh thái phần mềm toàn diện, và quan hệ đối tác chiến lược với các đại gia công nghệ như Microsoft, Google, Amazon."

Quy trình này minh họa sức mạnh cốt lõi của ReAct: khả năng điều chỉnh linh hoạt dựa trên phản hồi của môi trường. Không giống như một chương trình cứng nhắc với các bước được định trước, Agent ReAct có thể quyết định số lượng vòng lặp Thought-Action-Observation cần thiết tùy theo độ phức tạp của vấn đề. Điều này đặc biệt hữu ích khi xử lý các tác vụ mở, nơi không có công thức chuẩn nào có thể áp dụng một cách máy móc.

## Plan-and-Solve: Từ mục tiêu lớn đến các bước nhỏ

Nếu ReAct giúp Agent "suy nghĩ trong khi hành động", thì Plan-and-Solve tập trung vào việc "lập kế hoạch trước khi hành động". Đây là một cải tiến quan trọng, đặc biệt khi đối mặt với các vấn đề phức tạp đòi hỏi nhiều bước phụ thuộc lẫn nhau. Thay vì nhảy ngay vào hành động và có thể đi sai hướng, Agent trước tiên phân tích toàn bộ nhiệm vụ, chia nhỏ thành các sub-task, xác định thứ tự ưu tiên, sau đó mới bắt đầu thực thi từng bước một.

Quay lại trường hợp của Minh Anh và kế hoạch học IELTS 3 tháng. Một Agent áp dụng Plan-and-Solve sẽ không vội vàng đưa ra lịch học ngay từ đầu. Thay vào đó, Agent sẽ bắt đầu bằng việc lập một "master plan" bao gồm các bước: (1) Đánh giá trình độ hiện tại của người học; (2) Xác định các điểm yếu cần cải thiện; (3) Chia 3 tháng thành các giai đoạn nhỏ với mục tiêu cụ thể cho mỗi giai đoạn; (4) Lựa chọn tài liệu và phương pháp học phù hợp; (5) Thiết lập cơ chế theo dõi và điều chỉnh. Sau khi có kế hoạch tổng thể này, Agent mới bắt đầu thực hiện từng bước, sử dụng các tool cần thiết như tra cứu tài liệu IELTS, tính toán phân bổ thời gian, hoặc tìm kiếm các khóa học online phù hợp.

Phương pháp Plan-and-Solve được nhóm nghiên cứu tại Đại học Ohio State và IBM Research giới thiệu vào cuối năm 2023, như một cách để cải thiện hiệu suất của các Agent khi xử lý multi-step reasoning. Trong một nghiên cứu được công bố tại hội nghị NeurIPS 2023, các Agent sử dụng Plan-and-Solve đạt độ chính xác cao hơn 15-25% so với ReAct thuần túy trong các bài toán toán học phức tạp, lập lịch trình, và tối ưu hóa tài nguyên. Lý do chính là việc lập kế hoạch trước giúp Agent tránh được các lỗi phổ biến như bỏ qua các bước quan trọng, lặp lại công việc không cần thiết, hoặc đi vào ngõ cụt rồi phải quay lại từ đầu.

Một điểm thú vị là Plan-and-Solve không loại bỏ ReAct, mà bổ sung cho nó. Giai đoạn "Plan" sử dụng Chain of Thought để suy luận và chia nhỏ vấn đề, trong khi giai đoạn "Solve" áp dụng ReAct để thực thi từng sub-task một cách linh hoạt. Sự kết hợp này tạo ra một Agent vừa có tầm nhìn tổng thể (từ trên xuống), vừa có khả năng thích ứng với chi tiết cụ thể (từ dưới lên).

## Ứng dụng thực tế trong giáo dục

Trong lĩnh vực giáo dục, sự kết hợp giữa ReAct và Plan-and-Solve mở ra những khả năng ấn tượng. Một startup giáo dục tại Singapore tên là LearnFlow đã triển khai một Agent dựa trên hai mô hình này để hỗ trợ sinh viên chuẩn bị các kỳ thi chuẩn hóa như SAT, GRE, và GMAT. Agent không chỉ đơn giản cung cấp bài tập, mà còn phân tích điểm mạnh và điểm yếu của từng học viên, lập kế hoạch học tập cá nhân hóa, gợi ý tài liệu phù hợp, và điều chỉnh chiến lược dựa trên tiến độ thực tế. Sau 6 tháng triển khai, LearnFlow báo cáo rằng học viên sử dụng Agent đạt điểm số trung bình cao hơn 18% so với nhóm học theo phương pháp truyền thống, và tỷ lệ hoàn thành khóa học tăng từ 62% lên 89%.

Một ví dụ khác đến từ Khan Academy, tổ chức giáo dục phi lợi nhuận lớn nhất thế giới với hơn 150 triệu người học. Vào đầu năm 2024, Khan Academy ra mắt "Khanmigo", một AI tutor sử dụng GPT-4 kết hợp với ReAct framework để hướng dẫn học sinh giải toán. Điểm đặc biệt là Khanmigo không đưa ra đáp án trực tiếp, mà dẫn dắt học sinh qua từng bước tư duy. Khi một học sinh gặp khó khăn với bài toán phương trình bậc hai, Khanmigo không nói "Đáp án là x = 3 và x = -2", mà hỏi: "Em có nhận thấy phương trình này có dạng ax² + bx + c = 0 không? Giá trị của a, b, c là bao nhiêu?" Sau khi học sinh trả lời, Khanmigo tiếp tục: "Tốt lắm! Bây giờ em nhớ công thức nghiệm của phương trình bậc hai không?" Quy trình này chính là ReAct trong thực tế—Thought (nhận biết cấu trúc bài toán), Action (đặt câu hỏi gợi mở), Observation (theo dõi phản hồi của học sinh), rồi Thought tiếp (quyết định bước tiếp theo).

Dữ liệu từ Khan Academy cho thấy học sinh tương tác với Khanmigo trung bình dành 40% thời gian nhiều hơn để làm bài tập toán so với khi học một mình, và tỷ lệ làm đúng bài tập khó tăng từ 54% lên 73% chỉ sau 2 tháng. Điều này minh chứng rằng ReAct không chỉ là một kỹ thuật lý thuyết, mà có tác động thực sự đến hiệu quả học tập.

## Thách thức và giải pháp khi triển khai

Mặc dù ReAct và Plan-and-Solve mang lại nhiều lợi ích, việc triển khai chúng trong môi trường production không phải không có thách thức. Một trong những vấn đề lớn nhất là chi phí và thời gian xử lý. Mỗi vòng lặp Thought-Action-Observation đều đòi hỏi một lần gọi API đến mô hình ngôn ngữ lớn, và với các bài toán phức tạp, số vòng lặp có thể lên đến 10-15 lần. Nếu mỗi lần gọi API mất 2-3 giây và tốn $0.01, một nhiệm vụ hoàn chỉnh có thể mất nửa phút và tốn $0.15. Đối với một dịch vụ giáo dục phục vụ hàng nghìn học sinh mỗi ngày, con số này nhanh chóng trở nên đáng kể.

Để giải quyết vấn đề này, các nhà phát triển thực tế thường áp dụng một số chiến lược tối ưu. Thứ nhất là "caching kết quả"—nếu nhiều học sinh hỏi câu hỏi tương tự hoặc giống nhau (ví dụ: "Giải thích định lý Pythagore"), Agent không cần phải chạy lại toàn bộ quy trình ReAct mà có thể sử dụng kết quả đã lưu trữ, chỉ điều chỉnh nhẹ theo ngữ cảnh cụ thể. Thứ hai là "early stopping"—Agent được thiết kế để nhận biết khi nào đã có đủ thông tin để trả lời, tránh việc thực hiện thêm các vòng lặp không cần thiết. Thứ ba là "hybrid approach"—kết hợp ReAct với các phương pháp truyền thống: chỉ kích hoạt ReAct khi gặp câu hỏi phức tạp, còn các câu hỏi đơn giản sẽ được xử lý bằng rule-based system hoặc retrieval đơn thuần.

Một thách thức khác là việc đảm bảo Agent không bị "lạc hướng" trong quá trình thực thi. Đôi khi, Agent có thể rơi vào vòng lặp vô hạn—liên tục thực hiện các action mà không đạt được tiến triển thực sự. Ví dụ: Agent cần tra cứu thông tin về "GDP của Việt Nam năm 2024", nhưng công cụ tìm kiếm trả về kết quả không rõ ràng, Agent quyết định thử lại với query khác, rồi lại nhận được kết quả không thỏa mãn, cứ thế lặp đi lặp lại. Để phòng tránh, các Agent production thường được thiết lập giới hạn số vòng lặp tối đa (ví dụ: 10 lần), và có cơ chế "fallback"—nếu sau N lần thử mà vẫn không đạt kết quả, Agent sẽ trả lời thẳng thắn: "Tôi chưa tìm được thông tin chính xác về câu hỏi này, bạn có thể cung cấp thêm chi tiết hoặc thử lại sau?"

Cuối cùng, vấn đề về "explainability" (khả năng giải thích) cũng rất quan trọng, đặc biệt trong giáo dục. Khi một Agent đưa ra kế hoạch học tập hoặc lời giải cho bài toán, giáo viên và phụ huynh muốn biết Agent đã suy luận như thế nào để đến kết quả đó. May mắn thay, ReAct và Plan-and-Solve tự nhiên tạo ra một "audit trail" chi tiết—mỗi bước Thought và Action đều được ghi lại, tạo thành một chuỗi lý luận minh bạch. Các nền tảng giáo dục tiên tiến như Duolingo Max và Coursera đang thử nghiệm các giao diện cho phép người dùng xem "bên trong đầu" của Agent, theo dõi từng bước suy luận và hành động mà Agent đã thực hiện. Điều này không chỉ tăng niềm tin của người dùng, mà còn giúp các nhà phát triển debug và cải thiện Agent hiệu quả hơn.

## Tương lai của Reasoning Agents

Với sự phát triển nhanh chóng của các mô hình ngôn ngữ lớn thế hệ mới—như GPT-5, Claude Opus, và Gemini Ultra được dự kiến ra mắt trong năm 2025—khả năng reasoning của các Agent sẽ còn mạnh mẽ hơn nhiều. Nghiên cứu hiện tại đang hướng tới "self-improving agents"—những Agent không chỉ thực thi nhiệm vụ, mà còn học hỏi từ kinh nghiệm của chính mình, tối ưu hóa chiến lược theo thời gian mà không cần can thiệp của con người. Ví dụ: một Agent dạy toán sau khi tương tác với hàng nghìn học sinh, có thể tự động nhận ra rằng học sinh thường gặp khó khăn với một loại bài tập cụ thể, và điều chỉnh cách giải thích của mình để rõ ràng hơn.

OpenAI đã chia sẻ trong một bài blog vào tháng 9/2024 rằng họ đang phát triển "o1"—một mô hình được thiết kế đặc biệt để "suy nghĩ sâu" trước khi trả lời, với khả năng reasoning vượt xa các mô hình hiện tại. Trong các bài test toán Olympic và lập trình thi đấu, o1 đạt độ chính xác gần 90%, so với khoảng 50-60% của GPT-4. Nếu xu hướng này tiếp tục, chúng ta sẽ sớm có những Agent có thể xử lý các vấn đề phức tạp mà trước đây chỉ có chuyên gia giỏi nhất mới làm được—từ thiết kế chương trình học cá nhân hóa cho từng học sinh, đến tư vấn nghề nghiệp dựa trên phân tích sâu về xu hướng thị trường lao động, đến hỗ trợ nghiên cứu khoa học bằng cách tổng hợp và phân tích hàng nghìn bài báo chuyên ngành.

Đối với những ai đang xây dựng các hệ thống giáo dục tự động, việc nắm vững ReAct và Plan-and-Solve không chỉ là một lợi thế kỹ thuật, mà là yếu tố then chốt để tạo ra những trải nghiệm học tập thực sự có giá trị, thay vì chỉ là những chatbot đơn giản trả lời câu hỏi một cách máy móc. Chìa khóa nằm ở việc thiết kế các Agent không chỉ "biết nhiều", mà còn "biết cách suy nghĩ" và "biết cách hành động" một cách thông minh và linh hoạt.

